{"docid_partnum": ["GUM_interview_onion", 0], "doc_string": "The Onion : An interview with ' America 's Finest News Source ' Sunday, November 25, 2007 How The Onion writes an issue This exclusive interview features first-hand journalism by a Wikinews reporter. See the collaboration page for more details. How do you decide on the stories? We do everything backwards here. We start with the headline and then flesh out the story, as opposed to The New York Times, which writes the issue and then has a headline editor to make it snappy. We start with a joke. We read about six hundred to eight hundred headline ideas on a Monday coming from our staff and a small group of writers outside \u2014 a contributing core. We whittle that down on a Monday to about a hundred, come in Tuesday and pick an issue and brainstorm with the whole editorial staff ; all fifteen of us. Then we assign a headline to a specific writer to execute. We go through a number of drafts and then have the editors pick it up and assign the photojournalism aspect of it to our graphic design team, who adds the visual aspect to it. The editors punch it up over the last couple of days and then it goes out over the Internet and into the print edition. So you do n\u2019t have writers coming up with a story and headline, but you will instead have a team of writers choosing the best headlines and then assign it to a particular writer who was not necessarily involved? Writers will occasionally write their own headlines, but we come up with a list of 15 or 20 headline ideas, what we think will make a good story and then we assign it based upon what people \u2019s writing strengths are. We have some people who are great at politics ; some people we give all the war stuff to ; someone who is in charge of the Britney Spears story of the week \u2014 the entertainment stories. The headlines Editorial Manager Chet Clem and President Sean Mills. Image : David Shankbone It seems like some publications, like AM New York, always have a Britney Spears story ; is there anything similar with The Onion where they continually revisit a topic or person? No, not necessarily. We are a little less reactionary. We tend to target the zeitgeist more than anything. We \u2019ll hit the mainstream media \u2019s portrayal of the entertainment world as much as we \u2019ll hit characters in the entertainment world. We \u2019ll attack People Magazine \u2019s coverage of Britney as much as Britney. In an interview with Terry Gross, Stephen Colbert said of his time at Second City that they had decided on not doing political humor and, in particular, hackneyed political humor such as Ted Kennedy drinking jokes. They felt it was overdone, mean-spirited and not funny. Do your writers have similar rules of thumb? We do n\u2019t have any rules or known lines we wo n\u2019t cross. We have an understanding based upon having the same writers in the back room for years, and those writers training the new writers as they come in. There is an understanding in the room. If it makes the room laugh, it probably ends up in the paper. One example is we ran an article a couple of years back that was, \" No Jennifer Lopez News Today\" . That was our reaction to all of the J-Lo stuff. We were n\u2019t going to touch on her dress, or who she was dating. Just the fact that those were the lead stories for so many days, in everything from US Weekly to Time Magazine. I think it \u2019s important we have an original take on those things. I think it \u2019s similar to what Colbert said to Terry Gross. We do n\u2019t want to just traffic in the same 24 hour news cycle. There \u2019s a 24 hour comedy news cycle that exists on all the late night talk shows. The Onion has a different creative process where we are not trying to hit everything in the 24 hours and on the same notes. We want an original take. If we choose to do something on J-Lo, it \u2019s going to be something like that, something less obvious. When you are going through the headlines, is it just you guys sitting around trying to crack each other up? It \u2019s the least amount of fun possible. Nah, I \u2019m kidding. It \u2019s actually more businesslike than you \u2019d imagine. It \u2019s very much like you are trying to make the room laugh, but the room has been a sort of captive audience for many many years now, so it takes a lot to make the room laugh. The best analogy I \u2019ve heard is when Rob Siegel, former editor-in-chief, likened it to wine tasting. It \u2019s this quiet experience where you are trying to soak in what the joke is, have we done anything like this, is it a unique take, what are other people doing. It \u2019s sort of like, \" Hmmm ... that \u2019s hilarious. That \u2019s really really funny\" rather than people falling off their chairs. It \u2019s more subdued than I think what most people would expect. It \u2019s more analytical and clinical? Not all the time, but it ca n\u2019t be a laugh a minute. Yeah, what you see on Studio 60 and 30 Rock, those are scripted writers rooms. Everything is funny there. There 's a lot of unfunny jokes that are told in a back room, that 's why they stay and die in that back room and do n\u2019t go out in The Onion. If someone is continually telling unfunny jokes, do you eventually fire them? That \u2019s why we are on the 10th floor to make sure they die when they get kicked out. It can be a real mess on Broadway. By the time you get to be a writer for The Onion, though, the odds are you are going to succeed because we make it pretty challenging. You go through quite a bit. You will already have demonstrated a pretty long successful record of writing stuff for us before you will be in that room on a daily basis. But if somebody wakes up one morning and suddenly no longer is funny, then yeah, head first, out the door as quickly as possible, and as sadistically as possible.", "sentences": [{"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["The", "Onion", ":", "An", "interview", "with", "'", "America", "'s", "Finest", "News", "Source", "'"], "mentions": [[1, [0, 2]], [2, [3, 13]], [1, [7, 12]], [3, [7, 9]], [4, [10, 11]]], "sent_string": "The Onion : An interview with ' America 's Finest News Source '", "mentions_string": {"The Onion": [1, [0, 2]], "An interview with ' America 's Finest News Source '": [2, [3, 13]], "America 's Finest News Source": [1, [7, 12]], "America 's": [3, [7, 9]], "News": [4, [10, 11]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["Sunday", ",", "November", "25", ",", "2007"], "mentions": [[5, [0, 1]], [5, [2, 6]], [8, [5, 6]]], "sent_string": "Sunday, November 25, 2007", "mentions_string": {"Sunday": [5, [0, 1]], "November 25, 2007": [5, [2, 6]], "2007": [8, [5, 6]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["How", "The", "Onion", "writes", "an", "issue"], "mentions": [[1, [1, 3]], [10, [4, 6]]], "sent_string": "How The Onion writes an issue", "mentions_string": {"The Onion": [1, [1, 3]], "an issue": [10, [4, 6]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["This", "exclusive", "interview", "features", "first", "-", "hand", "journalism", "by", "a", "Wikinews", "reporter", "."], "mentions": [[2, [0, 3]], [11, [4, 12]], [12, [9, 12]], [13, [10, 11]]], "sent_string": "This exclusive interview features first-hand journalism by a Wikinews reporter.", "mentions_string": {"This exclusive interview": [2, [0, 3]], "first-hand journalism by a Wikinews reporter": [11, [4, 12]], "a Wikinews reporter": [12, [9, 12]], "Wikinews": [13, [10, 11]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["See", "the", "collaboration", "page", "for", "more", "details", "."], "mentions": [[15, [1, 4]], [16, [2, 3]], [18, [5, 7]]], "sent_string": "See the collaboration page for more details.", "mentions_string": {"the collaboration page": [15, [1, 4]], "collaboration": [16, [2, 3]], "more details": [18, [5, 7]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["How", "do", "you", "decide", "on", "the", "stories", "?"], "mentions": [[19, [2, 3]], [21, [5, 7]]], "sent_string": "How do you decide on the stories?", "mentions_string": {"you": [19, [2, 3]], "the stories": [21, [5, 7]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["We", "do", "everything", "backwards", "here", "."], "mentions": [[19, [0, 1]], [22, [2, 3]], [1, [4, 5]]], "sent_string": "We do everything backwards here.", "mentions_string": {"We": [19, [0, 1]], "everything": [22, [2, 3]], "here": [1, [4, 5]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["We", "start", "with", "the", "headline", "and", "then", "flesh", "out", "the", "story", ",", "as", "opposed", "to", "The", "New", "York", "Times", ",", "which", "writes", "the", "issue", "and", "then", "has", "a", "headline", "editor", "to", "make", "it", "snappy", "."], "mentions": [[19, [0, 1]], [27, [3, 5]], [28, [9, 11]], [29, [15, 34]], [30, [16, 18]], [31, [22, 24]], [32, [27, 30]], [33, [28, 29]], [27, [32, 33]]], "sent_string": "We start with the headline and then flesh out the story, as opposed to The New York Times, which writes the issue and then has a headline editor to make it snappy.", "mentions_string": {"We": [19, [0, 1]], "the headline": [27, [3, 5]], "the story": [28, [9, 11]], "The New York Times, which writes the issue and then has a headline editor to make it snappy": [29, [15, 34]], "New York": [30, [16, 18]], "the issue": [31, [22, 24]], "a headline editor": [32, [27, 30]], "headline": [33, [28, 29]], "it": [27, [32, 33]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["We", "start", "with", "a", "joke", "."], "mentions": [[19, [0, 1]], [37, [3, 5]]], "sent_string": "We start with a joke.", "mentions_string": {"We": [19, [0, 1]], "a joke": [37, [3, 5]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["We", "read", "about", "six", "hundred", "to", "eight", "hundred", "headline", "ideas", "on", "a", "Monday", "coming", "from", "our", "staff", "and", "a", "small", "group", "of", "writers", "outside", "\u2014", "a", "contributing", "core", "."], "mentions": [[19, [0, 1]], [39, [2, 10]], [33, [8, 9]], [41, [11, 13]], [42, [15, 24]], [43, [15, 17]], [19, [15, 16]], [45, [18, 24]], [42, [25, 28]]], "sent_string": "We read about six hundred to eight hundred headline ideas on a Monday coming from our staff and a small group of writers outside \u2014 a contributing core.", "mentions_string": {"We": [19, [0, 1]], "about six hundred to eight hundred headline ideas": [39, [2, 10]], "headline": [33, [8, 9]], "a Monday": [41, [11, 13]], "our staff and a small group of writers outside": [42, [15, 24]], "our staff": [43, [15, 17]], "our": [19, [15, 16]], "a small group of writers outside": [45, [18, 24]], "a contributing core": [42, [25, 28]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["We", "whittle", "that", "down", "on", "a", "Monday", "to", "about", "a", "hundred", ",", "come", "in", "Tuesday", "and", "pick", "an", "issue", "and", "brainstorm", "with", "the", "whole", "editorial", "staff", ";", "all", "fifteen", "of", "us", "."], "mentions": [[19, [0, 1]], [39, [2, 3]], [41, [5, 7]], [48, [8, 11]], [49, [14, 15]], [51, [17, 19]], [43, [22, 26]], [43, [27, 31]]], "sent_string": "We whittle that down on a Monday to about a hundred, come in Tuesday and pick an issue and brainstorm with the whole editorial staff ; all fifteen of us.", "mentions_string": {"We": [19, [0, 1]], "that": [39, [2, 3]], "a Monday": [41, [5, 7]], "about a hundred": [48, [8, 11]], "Tuesday": [49, [14, 15]], "an issue": [51, [17, 19]], "the whole editorial staff": [43, [22, 26]], "all fifteen of us": [43, [27, 31]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["Then", "we", "assign", "a", "headline", "to", "a", "specific", "writer", "to", "execute", "."], "mentions": [[19, [1, 2]], [53, [3, 5]], [54, [6, 9]]], "sent_string": "Then we assign a headline to a specific writer to execute.", "mentions_string": {"we": [19, [1, 2]], "a headline": [53, [3, 5]], "a specific writer": [54, [6, 9]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["We", "go", "through", "a", "number", "of", "drafts", "and", "then", "have", "the", "editors", "pick", "it", "up", "and", "assign", "the", "photojournalism", "aspect", "of", "it", "to", "our", "graphic", "design", "team", ",", "who", "adds", "the", "visual", "aspect", "to", "it", "."], "mentions": [[19, [0, 1]], [56, [3, 7]], [43, [10, 12]], [57, [13, 14]], [59, [17, 22]], [60, [18, 19]], [57, [21, 22]], [63, [23, 35]], [19, [23, 24]], [65, [24, 26]], [66, [30, 33]], [57, [34, 35]]], "sent_string": "We go through a number of drafts and then have the editors pick it up and assign the photojournalism aspect of it to our graphic design team, who adds the visual aspect to it.", "mentions_string": {"We": [19, [0, 1]], "a number of drafts": [56, [3, 7]], "the editors": [43, [10, 12]], "it": [57, [34, 35]], "the photojournalism aspect of it": [59, [17, 22]], "photojournalism": [60, [18, 19]], "our graphic design team, who adds the visual aspect to it": [63, [23, 35]], "our": [19, [23, 24]], "graphic design": [65, [24, 26]], "the visual aspect": [66, [30, 33]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["The", "editors", "punch", "it", "up", "over", "the", "last", "couple", "of", "days", "and", "then", "it", "goes", "out", "over", "the", "Internet", "and", "into", "the", "print", "edition", "."], "mentions": [[43, [0, 2]], [57, [3, 4]], [69, [6, 11]], [57, [13, 14]], [71, [17, 19]], [72, [21, 24]]], "sent_string": "The editors punch it up over the last couple of days and then it goes out over the Internet and into the print edition.", "mentions_string": {"The editors": [43, [0, 2]], "it": [57, [13, 14]], "the last couple of days": [69, [6, 11]], "the Internet": [71, [17, 19]], "the print edition": [72, [21, 24]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["So", "you", "do", "n\u2019t", "have", "writers", "coming", "up", "with", "a", "story", "and", "headline", ",", "but", "you", "will", "instead", "have", "a", "team", "of", "writers", "choosing", "the", "best", "headlines", "and", "then", "assign", "it", "to", "a", "particular", "writer", "who", "was", "not", "necessarily", "involved", "?"], "mentions": [[73, [1, 2]], [74, [5, 6]], [77, [9, 13]], [73, [15, 16]], [79, [19, 23]], [80, [24, 27]], [81, [30, 31]], [83, [32, 40]]], "sent_string": "So you do n\u2019t have writers coming up with a story and headline, but you will instead have a team of writers choosing the best headlines and then assign it to a particular writer who was not necessarily involved?", "mentions_string": {"you": [73, [15, 16]], "writers": [74, [5, 6]], "a story and headline": [77, [9, 13]], "a team of writers": [79, [19, 23]], "the best headlines": [80, [24, 27]], "it": [81, [30, 31]], "a particular writer who was not necessarily involved": [83, [32, 40]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["Writers", "will", "occasionally", "write", "their", "own", "headlines", ",", "but", "we", "come", "up", "with", "a", "list", "of", "15", "or", "20", "headline", "ideas", ",", "what", "we", "think", "will", "make", "a", "good", "story", "and", "then", "we", "assign", "it", "based", "upon", "what", "people", "\u2019s", "writing", "strengths", "are", "."], "mentions": [[74, [0, 1]], [85, [4, 7]], [74, [4, 5]], [19, [9, 10]], [88, [13, 21]], [89, [16, 21]], [33, [19, 20]], [19, [23, 24]], [92, [27, 30]], [19, [32, 33]], [92, [34, 35]], [95, [38, 42]], [74, [38, 40]], [96, [40, 41]]], "sent_string": "Writers will occasionally write their own headlines, but we come up with a list of 15 or 20 headline ideas, what we think will make a good story and then we assign it based upon what people \u2019s writing strengths are.", "mentions_string": {"Writers": [74, [0, 1]], "their own headlines": [85, [4, 7]], "their": [74, [4, 5]], "we": [19, [32, 33]], "a list of 15 or 20 headline ideas": [88, [13, 21]], "15 or 20 headline ideas": [89, [16, 21]], "headline": [33, [19, 20]], "a good story": [92, [27, 30]], "it": [92, [34, 35]], "people \u2019s writing strengths": [95, [38, 42]], "people \u2019s": [74, [38, 40]], "writing": [96, [40, 41]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["We", "have", "some", "people", "who", "are", "great", "at", "politics", ";", "some", "people", "we", "give", "all", "the", "war", "stuff", "to", ";", "someone", "who", "is", "in", "charge", "of", "the", "Britney", "Spears", "story", "of", "the", "week", "\u2014", "the", "entertainment", "stories", "."], "mentions": [[19, [0, 1]], [99, [2, 9]], [100, [8, 9]], [102, [10, 19]], [19, [12, 13]], [104, [14, 18]], [105, [16, 17]], [107, [20, 37]], [108, [26, 33]], [109, [27, 29]], [110, [31, 33]], [111, [34, 37]], [112, [35, 36]]], "sent_string": "We have some people who are great at politics ; some people we give all the war stuff to ; someone who is in charge of the Britney Spears story of the week \u2014 the entertainment stories.", "mentions_string": {"We": [19, [0, 1]], "some people who are great at politics": [99, [2, 9]], "politics": [100, [8, 9]], "some people we give all the war stuff to": [102, [10, 19]], "we": [19, [12, 13]], "all the war stuff": [104, [14, 18]], "war": [105, [16, 17]], "someone who is in charge of the Britney Spears story of the week \u2014 the entertainment stories": [107, [20, 37]], "the Britney Spears story of the week": [108, [26, 33]], "Britney Spears": [109, [27, 29]], "the week": [110, [31, 33]], "the entertainment stories": [111, [34, 37]], "entertainment": [112, [35, 36]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["The", "headlines"], "mentions": [[114, [0, 2]]], "sent_string": "The headlines", "mentions_string": {"The headlines": [114, [0, 2]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["Editorial", "Manager", "Chet", "Clem", "and", "President", "Sean", "Mills", "."], "mentions": [[115, [0, 4]], [116, [5, 8]]], "sent_string": "Editorial Manager Chet Clem and President Sean Mills.", "mentions_string": {"Editorial Manager Chet Clem": [115, [0, 4]], "President Sean Mills": [116, [5, 8]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["Image", ":", "David", "Shankbone"], "mentions": [[117, [0, 1]], [119, [2, 4]]], "sent_string": "Image : David Shankbone", "mentions_string": {"Image": [117, [0, 1]], "David Shankbone": [119, [2, 4]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["It", "seems", "like", "some", "publications", ",", "like", "AM", "New", "York", ",", "always", "have", "a", "Britney", "Spears", "story", ";"], "mentions": [[120, [0, 1]], [120, [3, 17]], [122, [3, 10]], [123, [7, 10]], [30, [8, 10]], [108, [13, 17]], [109, [14, 16]]], "sent_string": "It seems like some publications, like AM New York, always have a Britney Spears story ;", "mentions_string": {"It": [120, [0, 1]], "some publications, like AM New York, always have a Britney Spears story": [120, [3, 17]], "some publications, like AM New York": [122, [3, 10]], "AM New York": [123, [7, 10]], "New York": [30, [8, 10]], "a Britney Spears story": [108, [13, 17]], "Britney Spears": [109, [14, 16]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["is", "there", "anything", "similar", "with", "The", "Onion", "where", "they", "continually", "revisit", "a", "topic", "or", "person", "?"], "mentions": [[124, [2, 4]], [1, [5, 7]], [1, [8, 9]], [126, [11, 13]], [127, [14, 15]]], "sent_string": "is there anything similar with The Onion where they continually revisit a topic or person?", "mentions_string": {"anything similar": [124, [2, 4]], "The Onion": [1, [5, 7]], "they": [1, [8, 9]], "a topic": [126, [11, 13]], "person": [127, [14, 15]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["No", ",", "not", "necessarily", "."], "mentions": [], "sent_string": "No, not necessarily.", "mentions_string": {}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["We", "are", "a", "little", "less", "reactionary", "."], "mentions": [[19, [0, 1]]], "sent_string": "We are a little less reactionary.", "mentions_string": {"We": [19, [0, 1]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["We", "tend", "to", "target", "the", "zeitgeist", "more", "than", "anything", "."], "mentions": [[19, [0, 1]], [131, [4, 6]], [132, [8, 9]]], "sent_string": "We tend to target the zeitgeist more than anything.", "mentions_string": {"We": [19, [0, 1]], "the zeitgeist": [131, [4, 6]], "anything": [132, [8, 9]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["We", "\u2019ll", "hit", "the", "mainstream", "media", "\u2019s", "portrayal", "of", "the", "entertainment", "world", "as", "much", "as", "we", "\u2019ll", "hit", "characters", "in", "the", "entertainment", "world", "."], "mentions": [[19, [0, 1]], [135, [3, 12]], [136, [3, 7]], [137, [9, 12]], [112, [10, 11]], [19, [15, 16]], [140, [18, 23]], [137, [20, 23]], [112, [21, 22]]], "sent_string": "We \u2019ll hit the mainstream media \u2019s portrayal of the entertainment world as much as we \u2019ll hit characters in the entertainment world.", "mentions_string": {"We": [19, [0, 1]], "the mainstream media \u2019s portrayal of the entertainment world": [135, [3, 12]], "the mainstream media \u2019s": [136, [3, 7]], "the entertainment world": [137, [20, 23]], "entertainment": [112, [21, 22]], "we": [19, [15, 16]], "characters in the entertainment world": [140, [18, 23]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["We", "\u2019ll", "attack", "People", "Magazine", "\u2019s", "coverage", "of", "Britney", "as", "much", "as", "Britney", "."], "mentions": [[19, [0, 1]], [143, [3, 13]], [144, [3, 6]], [109, [8, 9]], [109, [12, 13]]], "sent_string": "We \u2019ll attack People Magazine \u2019s coverage of Britney as much as Britney.", "mentions_string": {"We": [19, [0, 1]], "People Magazine \u2019s coverage of Britney as much as Britney": [143, [3, 13]], "People Magazine \u2019s": [144, [3, 6]], "Britney": [109, [12, 13]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["In", "an", "interview", "with", "Terry", "Gross", ",", "Stephen", "Colbert", "said", "of", "his", "time", "at", "Second", "City", "that", "they", "had", "decided", "on", "not", "doing", "political", "humor", "and", ",", "in", "particular", ",", "hackneyed", "political", "humor", "such", "as", "Ted", "Kennedy", "drinking", "jokes", "."], "mentions": [[147, [1, 6]], [148, [4, 6]], [149, [7, 9]], [150, [11, 16]], [149, [11, 12]], [152, [14, 16]], [152, [17, 18]], [154, [23, 25]], [155, [30, 39]], [156, [35, 39]], [157, [35, 37]]], "sent_string": "In an interview with Terry Gross, Stephen Colbert said of his time at Second City that they had decided on not doing political humor and, in particular, hackneyed political humor such as Ted Kennedy drinking jokes.", "mentions_string": {"an interview with Terry Gross": [147, [1, 6]], "Terry Gross": [148, [4, 6]], "Stephen Colbert": [149, [7, 9]], "his time at Second City": [150, [11, 16]], "his": [149, [11, 12]], "Second City": [152, [14, 16]], "they": [152, [17, 18]], "political humor": [154, [23, 25]], "hackneyed political humor such as Ted Kennedy drinking jokes": [155, [30, 39]], "Ted Kennedy drinking jokes": [156, [35, 39]], "Ted Kennedy": [157, [35, 37]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["They", "felt", "it", "was", "overdone", ",", "mean", "-", "spirited", "and", "not", "funny", "."], "mentions": [[152, [0, 1]], [155, [2, 3]]], "sent_string": "They felt it was overdone, mean-spirited and not funny.", "mentions_string": {"They": [152, [0, 1]], "it": [155, [2, 3]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["Do", "your", "writers", "have", "similar", "rules", "of", "thumb", "?"], "mentions": [[74, [1, 3]], [19, [1, 2]], [161, [4, 8]]], "sent_string": "Do your writers have similar rules of thumb?", "mentions_string": {"your writers": [74, [1, 3]], "your": [19, [1, 2]], "similar rules of thumb": [161, [4, 8]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["We", "do", "n\u2019t", "have", "any", "rules", "or", "known", "lines", "we", "wo", "n\u2019t", "cross", "."], "mentions": [[19, [0, 1]], [163, [4, 6]], [164, [7, 13]], [19, [9, 10]]], "sent_string": "We do n\u2019t have any rules or known lines we wo n\u2019t cross.", "mentions_string": {"We": [19, [0, 1]], "any rules": [163, [4, 6]], "known lines we wo n\u2019t cross": [164, [7, 13]], "we": [19, [9, 10]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["We", "have", "an", "understanding", "based", "upon", "having", "the", "same", "writers", "in", "the", "back", "room", "for", "years", ",", "and", "those", "writers", "training", "the", "new", "writers", "as", "they", "come", "in", "."], "mentions": [[19, [0, 1]], [167, [2, 4]], [74, [7, 10]], [168, [11, 14]], [74, [18, 20]], [74, [21, 24]], [74, [25, 26]]], "sent_string": "We have an understanding based upon having the same writers in the back room for years, and those writers training the new writers as they come in.", "mentions_string": {"We": [19, [0, 1]], "an understanding": [167, [2, 4]], "the same writers": [74, [7, 10]], "the back room": [168, [11, 14]], "those writers": [74, [18, 20]], "the new writers": [74, [21, 24]], "they": [74, [25, 26]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["There", "is", "an", "understanding", "in", "the", "room", "."], "mentions": [[167, [2, 4]], [168, [5, 7]]], "sent_string": "There is an understanding in the room.", "mentions_string": {"an understanding": [167, [2, 4]], "the room": [168, [5, 7]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["If", "it", "makes", "the", "room", "laugh", ",", "it", "probably", "ends", "up", "in", "the", "paper", "."], "mentions": [[170, [1, 2]], [168, [3, 5]], [170, [7, 8]], [173, [12, 14]]], "sent_string": "If it makes the room laugh, it probably ends up in the paper.", "mentions_string": {"it": [170, [7, 8]], "the room": [168, [3, 5]], "the paper": [173, [12, 14]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["One", "example", "is", "we", "ran", "an", "article", "a", "couple", "of", "years", "back", "that", "was", ",", "\"", "No", "Jennifer", "Lopez", "News", "Today", "\"", "."], "mentions": [[174, [0, 2]], [19, [3, 4]], [176, [5, 22]], [177, [7, 11]], [178, [15, 22]], [176, [17, 20]], [179, [17, 19]], [180, [20, 21]]], "sent_string": "One example is we ran an article a couple of years back that was, \" No Jennifer Lopez News Today\" .", "mentions_string": {"One example": [174, [0, 2]], "we": [19, [3, 4]], "an article a couple of years back that was, \" No Jennifer Lopez News Today\"": [176, [5, 22]], "a couple of years": [177, [7, 11]], "\" No Jennifer Lopez News Today\"": [178, [15, 22]], "Jennifer Lopez News": [176, [17, 20]], "Jennifer Lopez": [179, [17, 19]], "Today": [180, [20, 21]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["That", "was", "our", "reaction", "to", "all", "of", "the", "J", "-", "Lo", "stuff", "."], "mentions": [[178, [0, 1]], [178, [2, 12]], [19, [2, 3]], [184, [5, 12]], [179, [8, 11]]], "sent_string": "That was our reaction to all of the J-Lo stuff.", "mentions_string": {"That": [178, [0, 1]], "our reaction to all of the J-Lo stuff": [178, [2, 12]], "our": [19, [2, 3]], "all of the J-Lo stuff": [184, [5, 12]], "J-Lo": [179, [8, 11]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["We", "were", "n\u2019t", "going", "to", "touch", "on", "her", "dress", ",", "or", "who", "she", "was", "dating", "."], "mentions": [[19, [0, 1]], [186, [7, 15]], [187, [7, 9]], [179, [7, 8]], [189, [11, 15]], [179, [12, 13]]], "sent_string": "We were n\u2019t going to touch on her dress, or who she was dating.", "mentions_string": {"We": [19, [0, 1]], "her dress, or who she was dating": [186, [7, 15]], "her dress": [187, [7, 9]], "her": [179, [7, 8]], "who she was dating": [189, [11, 15]], "she": [179, [12, 13]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["Just", "the", "fact", "that", "those", "were", "the", "lead", "stories", "for", "so", "many", "days", ",", "in", "everything", "from", "US", "Weekly", "to", "Time", "Magazine", "."], "mentions": [[191, [1, 22]], [186, [4, 5]], [186, [6, 9]], [193, [10, 13]], [194, [15, 22]], [195, [17, 19]], [3, [17, 18]], [197, [20, 22]]], "sent_string": "Just the fact that those were the lead stories for so many days, in everything from US Weekly to Time Magazine.", "mentions_string": {"the fact that those were the lead stories for so many days, in everything from US Weekly to Time Magazine": [191, [1, 22]], "those": [186, [4, 5]], "the lead stories": [186, [6, 9]], "so many days": [193, [10, 13]], "everything from US Weekly to Time Magazine": [194, [15, 22]], "US Weekly": [195, [17, 19]], "US": [3, [17, 18]], "Time Magazine": [197, [20, 22]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["I", "think", "it", "\u2019s", "important", "we", "have", "an", "original", "take", "on", "those", "things", "."], "mentions": [[198, [0, 1]], [199, [2, 3]], [199, [5, 13]], [19, [5, 6]], [203, [7, 13]], [186, [11, 13]]], "sent_string": "I think it \u2019s important we have an original take on those things.", "mentions_string": {"I": [198, [0, 1]], "it": [199, [2, 3]], "we have an original take on those things": [199, [5, 13]], "we": [19, [5, 6]], "an original take on those things": [203, [7, 13]], "those things": [186, [11, 13]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["I", "think", "it", "\u2019s", "similar", "to", "what", "Colbert", "said", "to", "Terry", "Gross", "."], "mentions": [[198, [0, 1]], [204, [2, 3]], [149, [7, 8]], [148, [10, 12]]], "sent_string": "I think it \u2019s similar to what Colbert said to Terry Gross.", "mentions_string": {"I": [198, [0, 1]], "it": [204, [2, 3]], "Colbert": [149, [7, 8]], "Terry Gross": [148, [10, 12]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["We", "do", "n\u2019t", "want", "to", "just", "traffic", "in", "the", "same", "24", "hour", "news", "cycle", "."], "mentions": [[204, [0, 14]], [19, [0, 1]], [209, [8, 14]], [210, [10, 12]], [211, [12, 13]]], "sent_string": "We do n\u2019t want to just traffic in the same 24 hour news cycle.", "mentions_string": {"We do n\u2019t want to just traffic in the same 24 hour news cycle": [204, [0, 14]], "We": [19, [0, 1]], "the same 24 hour news cycle": [209, [8, 14]], "24 hour": [210, [10, 12]], "news": [211, [12, 13]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["There", "\u2019s", "a", "24", "hour", "comedy", "news", "cycle", "that", "exists", "on", "all", "the", "late", "night", "talk", "shows", "."], "mentions": [[213, [2, 17]], [210, [3, 5]], [214, [5, 7]], [215, [11, 17]], [216, [13, 15]]], "sent_string": "There \u2019s a 24 hour comedy news cycle that exists on all the late night talk shows.", "mentions_string": {"a 24 hour comedy news cycle that exists on all the late night talk shows": [213, [2, 17]], "24 hour": [210, [3, 5]], "comedy news": [214, [5, 7]], "all the late night talk shows": [215, [11, 17]], "late night": [216, [13, 15]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["The", "Onion", "has", "a", "different", "creative", "process", "where", "we", "are", "not", "trying", "to", "hit", "everything", "in", "the", "24", "hours", "and", "on", "the", "same", "notes", "."], "mentions": [[1, [0, 2]], [217, [3, 24]], [19, [8, 9]], [218, [14, 15]], [210, [16, 19]], [221, [21, 24]]], "sent_string": "The Onion has a different creative process where we are not trying to hit everything in the 24 hours and on the same notes.", "mentions_string": {"The Onion": [1, [0, 2]], "a different creative process where we are not trying to hit everything in the 24 hours and on the same notes": [217, [3, 24]], "we": [19, [8, 9]], "everything": [218, [14, 15]], "the 24 hours": [210, [16, 19]], "the same notes": [221, [21, 24]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["We", "want", "an", "original", "take", "."], "mentions": [[19, [0, 1]], [203, [2, 5]]], "sent_string": "We want an original take.", "mentions_string": {"We": [19, [0, 1]], "an original take": [203, [2, 5]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["If", "we", "choose", "to", "do", "something", "on", "J", "-", "Lo", ",", "it", "\u2019s", "going", "to", "be", "something", "like", "that", ",", "something", "less", "obvious", "."], "mentions": [[19, [1, 2]], [224, [5, 10]], [179, [7, 10]], [224, [11, 12]], [224, [16, 19]], [178, [18, 19]], [224, [20, 23]]], "sent_string": "If we choose to do something on J-Lo, it \u2019s going to be something like that, something less obvious.", "mentions_string": {"we": [19, [1, 2]], "something on J-Lo": [224, [5, 10]], "J-Lo": [179, [7, 10]], "it": [224, [11, 12]], "something like that": [224, [16, 19]], "that": [178, [18, 19]], "something less obvious": [224, [20, 23]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["When", "you", "are", "going", "through", "the", "headlines", ",", "is", "it", "just", "you", "guys", "sitting", "around", "trying", "to", "crack", "each", "other", "up", "?"], "mentions": [[227, [0, 7]], [19, [1, 2]], [114, [5, 7]], [229, [9, 10]], [231, [11, 21]], [232, [11, 13]], [232, [18, 20]]], "sent_string": "When you are going through the headlines, is it just you guys sitting around trying to crack each other up?", "mentions_string": {"When you are going through the headlines": [227, [0, 7]], "you": [19, [1, 2]], "the headlines": [114, [5, 7]], "it": [229, [9, 10]], "you guys sitting around trying to crack each other up": [231, [11, 21]], "you guys": [232, [11, 13]], "each other": [232, [18, 20]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["It", "\u2019s", "the", "least", "amount", "of", "fun", "possible", "."], "mentions": [[231, [0, 1]], [234, [2, 8]], [235, [6, 7]]], "sent_string": "It \u2019s the least amount of fun possible.", "mentions_string": {"It": [231, [0, 1]], "the least amount of fun possible": [234, [2, 8]], "fun": [235, [6, 7]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["Nah", ",", "I", "\u2019m", "kidding", "."], "mentions": [[198, [2, 3]]], "sent_string": "Nah, I \u2019m kidding.", "mentions_string": {"I": [198, [2, 3]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["It", "\u2019s", "actually", "more", "businesslike", "than", "you", "\u2019d", "imagine", "."], "mentions": [[231, [0, 1]], [73, [6, 7]]], "sent_string": "It \u2019s actually more businesslike than you \u2019d imagine.", "mentions_string": {"It": [231, [0, 1]], "you": [73, [6, 7]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["It", "\u2019s", "very", "much", "like", "you", "are", "trying", "to", "make", "the", "room", "laugh", ",", "but", "the", "room", "has", "been", "a", "sort", "of", "captive", "audience", "for", "many", "many", "years", "now", ",", "so", "it", "takes", "a", "lot", "to", "make", "the", "room", "laugh", "."], "mentions": [[231, [0, 1]], [73, [5, 6]], [168, [10, 12]], [168, [15, 17]], [242, [19, 24]], [243, [25, 28]], [244, [31, 32]], [244, [35, 40]], [168, [37, 39]]], "sent_string": "It \u2019s very much like you are trying to make the room laugh, but the room has been a sort of captive audience for many many years now, so it takes a lot to make the room laugh.", "mentions_string": {"It": [231, [0, 1]], "you": [73, [5, 6]], "the room": [168, [37, 39]], "a sort of captive audience": [242, [19, 24]], "many many years": [243, [25, 28]], "it": [244, [31, 32]], "to make the room laugh": [244, [35, 40]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["The", "best", "analogy", "I", "\u2019ve", "heard", "is", "when", "Rob", "Siegel", ",", "former", "editor", "-", "in", "-", "chief", ",", "likened", "it", "to", "wine", "tasting", "."], "mentions": [[246, [0, 6]], [198, [3, 4]], [248, [8, 10]], [248, [11, 17]], [231, [19, 20]], [250, [21, 23]], [251, [21, 22]]], "sent_string": "The best analogy I \u2019ve heard is when Rob Siegel, former editor-in-chief, likened it to wine tasting.", "mentions_string": {"The best analogy I \u2019ve heard": [246, [0, 6]], "I": [198, [3, 4]], "Rob Siegel": [248, [8, 10]], "former editor-in-chief": [248, [11, 17]], "it": [231, [19, 20]], "wine tasting": [250, [21, 23]], "wine": [251, [21, 22]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["It", "\u2019s", "this", "quiet", "experience", "where", "you", "are", "trying", "to", "soak", "in", "what", "the", "joke", "is", ",", "have", "we", "done", "anything", "like", "this", ",", "is", "it", "a", "unique", "take", ",", "what", "are", "other", "people", "doing", "."], "mentions": [[231, [0, 1]], [231, [2, 16]], [73, [6, 7]], [255, [13, 15]], [232, [18, 19]], [257, [20, 23]], [255, [22, 23]], [255, [25, 26]], [260, [26, 29]], [261, [32, 34]]], "sent_string": "It \u2019s this quiet experience where you are trying to soak in what the joke is, have we done anything like this, is it a unique take, what are other people doing.", "mentions_string": {"It": [231, [0, 1]], "this quiet experience where you are trying to soak in what the joke is": [231, [2, 16]], "you": [73, [6, 7]], "the joke": [255, [13, 15]], "we": [232, [18, 19]], "anything like this": [257, [20, 23]], "this": [255, [22, 23]], "it": [255, [25, 26]], "a unique take": [260, [26, 29]], "other people": [261, [32, 34]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["It", "\u2019s", "sort", "of", "like", ",", "\"", "Hmmm", "...", "that", "\u2019s", "hilarious", ".", "That", "\u2019s", "really", "really", "funny", "\"", "rather", "than", "people", "falling", "off", "their", "chairs", "."], "mentions": [[231, [0, 1]], [255, [9, 10]], [255, [13, 14]], [262, [21, 22]], [267, [24, 26]], [262, [24, 25]]], "sent_string": "It \u2019s sort of like, \" Hmmm ... that \u2019s hilarious. That \u2019s really really funny\" rather than people falling off their chairs.", "mentions_string": {"It": [231, [0, 1]], "that": [255, [9, 10]], "That": [255, [13, 14]], "people": [262, [21, 22]], "their chairs": [267, [24, 26]], "their": [262, [24, 25]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["It", "\u2019s", "more", "subdued", "than", "I", "think", "what", "most", "people", "would", "expect", "."], "mentions": [[231, [0, 1]], [198, [5, 6]], [271, [8, 10]]], "sent_string": "It \u2019s more subdued than I think what most people would expect.", "mentions_string": {"It": [231, [0, 1]], "I": [198, [5, 6]], "most people": [271, [8, 10]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["It", "\u2019s", "more", "analytical", "and", "clinical", "?"], "mentions": [[231, [0, 1]]], "sent_string": "It \u2019s more analytical and clinical?", "mentions_string": {"It": [231, [0, 1]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["Not", "all", "the", "time", ",", "but", "it", "ca", "n\u2019t", "be", "a", "laugh", "a", "minute", "."], "mentions": [[273, [1, 4]], [231, [6, 7]], [275, [10, 12]], [276, [12, 14]]], "sent_string": "Not all the time, but it ca n\u2019t be a laugh a minute.", "mentions_string": {"all the time": [273, [1, 4]], "it": [231, [6, 7]], "a laugh": [275, [10, 12]], "a minute": [276, [12, 14]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["Yeah", ",", "what", "you", "see", "on", "Studio", "60", "and", "30", "Rock", ",", "those", "are", "scripted", "writers", "rooms", "."], "mentions": [[277, [2, 11]], [73, [3, 4]], [279, [6, 8]], [280, [9, 11]], [277, [12, 13]], [277, [14, 17]]], "sent_string": "Yeah, what you see on Studio 60 and 30 Rock, those are scripted writers rooms.", "mentions_string": {"what you see on Studio 60 and 30 Rock": [277, [2, 11]], "you": [73, [3, 4]], "Studio 60": [279, [6, 8]], "30 Rock": [280, [9, 11]], "those": [277, [12, 13]], "scripted writers rooms": [277, [14, 17]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["Everything", "is", "funny", "there", "."], "mentions": [[282, [0, 1]], [277, [3, 4]]], "sent_string": "Everything is funny there.", "mentions_string": {"Everything": [282, [0, 1]], "there": [277, [3, 4]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["There", "'s", "a", "lot", "of", "unfunny", "jokes", "that", "are", "told", "in", "a", "back", "room", ",", "that", "'s", "why", "they", "stay", "and", "die", "in", "that", "back", "room", "and", "do", "n\u2019t", "go", "out", "in", "The", "Onion", "."], "mentions": [[285, [0, 14]], [286, [2, 14]], [287, [11, 14]], [288, [15, 16]], [286, [18, 19]], [287, [23, 26]], [1, [32, 34]]], "sent_string": "There 's a lot of unfunny jokes that are told in a back room, that 's why they stay and die in that back room and do n\u2019t go out in The Onion.", "mentions_string": {"There 's a lot of unfunny jokes that are told in a back room": [285, [0, 14]], "a lot of unfunny jokes that are told in a back room": [286, [2, 14]], "a back room": [287, [11, 14]], "that": [288, [15, 16]], "they": [286, [18, 19]], "that back room": [287, [23, 26]], "The Onion": [1, [32, 34]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["If", "someone", "is", "continually", "telling", "unfunny", "jokes", ",", "do", "you", "eventually", "fire", "them", "?"], "mentions": [[291, [1, 2]], [286, [5, 7]], [73, [9, 10]], [291, [12, 13]]], "sent_string": "If someone is continually telling unfunny jokes, do you eventually fire them?", "mentions_string": {"someone": [291, [1, 2]], "unfunny jokes": [286, [5, 7]], "you": [73, [9, 10]], "them": [291, [12, 13]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["That", "\u2019s", "why", "we", "are", "on", "the", "10th", "floor", "to", "make", "sure", "they", "die", "when", "they", "get", "kicked", "out", "."], "mentions": [[293, [0, 1]], [293, [2, 9]], [232, [3, 4]], [298, [6, 9]], [293, [9, 19]], [291, [12, 13]], [291, [15, 16]]], "sent_string": "That \u2019s why we are on the 10th floor to make sure they die when they get kicked out.", "mentions_string": {"That": [293, [0, 1]], "why we are on the 10th floor": [293, [2, 9]], "we": [232, [3, 4]], "the 10th floor": [298, [6, 9]], "to make sure they die when they get kicked out": [293, [9, 19]], "they": [291, [15, 16]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["It", "can", "be", "a", "real", "mess", "on", "Broadway", "."], "mentions": [[299, [0, 1]], [299, [3, 8]], [303, [7, 8]]], "sent_string": "It can be a real mess on Broadway.", "mentions_string": {"It": [299, [0, 1]], "a real mess on Broadway": [299, [3, 8]], "Broadway": [303, [7, 8]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["By", "the", "time", "you", "get", "to", "be", "a", "writer", "for", "The", "Onion", ",", "though", ",", "the", "odds", "are", "you", "are", "going", "to", "succeed", "because", "we", "make", "it", "pretty", "challenging", "."], "mentions": [[305, [1, 12]], [73, [3, 4]], [307, [5, 12]], [308, [7, 12]], [1, [10, 12]], [309, [15, 17]], [73, [18, 19]], [232, [24, 25]], [310, [26, 27]]], "sent_string": "By the time you get to be a writer for The Onion, though, the odds are you are going to succeed because we make it pretty challenging.", "mentions_string": {"the time you get to be a writer for The Onion": [305, [1, 12]], "you": [73, [18, 19]], "to be a writer for The Onion": [307, [5, 12]], "a writer for The Onion": [308, [7, 12]], "The Onion": [1, [10, 12]], "the odds": [309, [15, 17]], "we": [232, [24, 25]], "it": [310, [26, 27]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["You", "go", "through", "quite", "a", "bit", "."], "mentions": [[73, [0, 1]], [315, [3, 6]]], "sent_string": "You go through quite a bit.", "mentions_string": {"You": [73, [0, 1]], "quite a bit": [315, [3, 6]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["You", "will", "already", "have", "demonstrated", "a", "pretty", "long", "successful", "record", "of", "writing", "stuff", "for", "us", "before", "you", "will", "be", "in", "that", "room", "on", "a", "daily", "basis", "."], "mentions": [[73, [0, 1]], [317, [5, 15]], [318, [12, 13]], [232, [14, 15]], [73, [16, 17]], [287, [20, 22]]], "sent_string": "You will already have demonstrated a pretty long successful record of writing stuff for us before you will be in that room on a daily basis.", "mentions_string": {"You": [73, [0, 1]], "a pretty long successful record of writing stuff for us": [317, [5, 15]], "stuff": [318, [12, 13]], "us": [232, [14, 15]], "you": [73, [16, 17]], "that room": [287, [20, 22]]}}, {"docid_partnum": ["GUM_interview_onion", 0], "tokens": ["But", "if", "somebody", "wakes", "up", "one", "morning", "and", "suddenly", "no", "longer", "is", "funny", ",", "then", "yeah", ",", "head", "first", ",", "out", "the", "door", "as", "quickly", "as", "possible", ",", "and", "as", "sadistically", "as", "possible", "."], "mentions": [[322, [2, 3]], [324, [5, 7]], [325, [17, 18]], [327, [21, 23]]], "sent_string": "But if somebody wakes up one morning and suddenly no longer is funny, then yeah, head first, out the door as quickly as possible, and as sadistically as possible.", "mentions_string": {"somebody": [322, [2, 3]], "one morning": [324, [5, 7]], "head": [325, [17, 18]], "the door": [327, [21, 23]]}}]}