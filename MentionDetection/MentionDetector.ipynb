{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-14 21:35:41 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
      "2021-09-14 21:35:41 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "| pos       | combined |\n",
      "| lemma     | combined |\n",
      "| depparse  | combined |\n",
      "========================\n",
      "\n",
      "2021-09-14 21:35:41 INFO: Use device: gpu\n",
      "2021-09-14 21:35:41 INFO: Loading: tokenize\n",
      "2021-09-14 21:35:44 INFO: Loading: pos\n",
      "2021-09-14 21:35:44 INFO: Loading: lemma\n",
      "2021-09-14 21:35:44 INFO: Loading: depparse\n",
      "2021-09-14 21:35:44 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "nlp = stanza.Pipeline(lang='en', processors='tokenize, mwt, pos, lemma, depparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''Some U.S. allies are complaining that President Bush is pushing conventional-arms talks too quickly, creating a risk that negotiators will make errors that could affect the security of Western Europe for years.'''\n",
    "def basic_mentions(text):\n",
    "    doc = nlp(text)\n",
    "    mentions  = []\n",
    "    for sentence in doc.sentences:\n",
    "        for word in sentence.words:\n",
    "            if word.pos in ['PRON', 'NOUN', 'PROPN', 'NUM']:\n",
    "                mentions.append({'word':word.text,\\\n",
    "                                 'parent':sentence.words[word.head-1].text if word.head > 0 else \"root\",\n",
    "                                 'parent_index':word.head,\n",
    "                                 'deprel':word.deprel,\n",
    "                                 'pos':word.pos,\\\n",
    "                                 'word_index':word.id,\\\n",
    "                                 'start_char':word.start_char,\\\n",
    "                                 'end_char':word.end_char,\\\n",
    "                                 'head':word.id})\n",
    "    return mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_mentions = basic_mentions(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "class DepGraph:\n",
    "    def __init__(self, text):\n",
    "        self.graph = defaultdict(dict)\n",
    "        self.paths = []\n",
    "        self.text = text\n",
    "        self.doc = nlp(text)\n",
    "        self.word_dict = {}\n",
    "        self.pos_dict = {}\n",
    "        self.char_span_dict = {}\n",
    "        self.mentions = []\n",
    "        self.buildgraph()\n",
    "    \n",
    "    def addEdge(self, u, v, rel):\n",
    "        '''adds edge u->v with relation rel'''\n",
    "        if(u in self.graph.keys()):\n",
    "            self.graph[u][v] = (rel)\n",
    "        else:\n",
    "            self.graph[u] = {} \n",
    "            self.graph[u][v] = (rel)\n",
    "            \n",
    "    def addinfo(self, u, word, pos, start, end):\n",
    "        self.word_dict[u] = word\n",
    "        self.pos_dict[u] = pos\n",
    "        self.char_span_dict[u] = [start, end]\n",
    "        \n",
    "    def buildgraph(self):\n",
    "        for sentence in self.doc.sentences:\n",
    "            for word in sentence.words:\n",
    "                parent_index = word.head\n",
    "                word_index = word.id\n",
    "                relation = word.deprel\n",
    "                self.addEdge(parent_index, word_index, relation)\n",
    "                self.addinfo(word_index, word.text, word.pos, word.start_char, word.end_char)\n",
    "        self.find_paths()\n",
    "        \n",
    "    def find_paths(self):\n",
    "        self.paths = []\n",
    "        self.depthFirst(0, -1, [])\n",
    "        list_of_paths = self.paths\n",
    "        self.paths = {}\n",
    "        for p in list_of_paths:\n",
    "            self.paths[p[-1]]  = p\n",
    "        \n",
    "    def depthFirst(self, currentVertex, previousVertex, visited):\n",
    "        visited.append(currentVertex)\n",
    "        for neighbour in self.graph[currentVertex]:\n",
    "            if neighbour not in visited:\n",
    "                self.depthFirst(neighbour, currentVertex, visited.copy())\n",
    "        self.paths.append(visited)\n",
    "        \n",
    "    def noun_phrase(self, currentVertex, visited):\n",
    "        visited.append(currentVertex)\n",
    "        \n",
    "        if len(self.graph[currentVertex])==0:\n",
    "            start_span = self.char_span_dict[currentVertex][0]\n",
    "            end_span = self.char_span_dict[currentVertex][1]\n",
    "            return [start_span, end_span]\n",
    "        \n",
    "        start = self.char_span_dict[currentVertex][0]\n",
    "        end = self.char_span_dict[currentVertex][1]\n",
    "        for child in self.graph[currentVertex].keys():\n",
    "            if child not in visited:\n",
    "                relation = self.graph[currentVertex][child]\n",
    "                if relation in ['compound', 'flat', 'fixed', 'det', 'amod', 'conj']:\n",
    "                    [start_new, end_new] = self.noun_phrase(child, visited.copy())\n",
    "                    start = min(start_new, start)\n",
    "                    end = max(end_new, end)  \n",
    "        return [start, end]\n",
    "            \n",
    "    def get_head_word(self, mention):\n",
    "        '''mention: text span of mention\n",
    "           g: dependency graph of entire sentence (of which mention is a sub-span) with paths of each node from root\n",
    "           returns: head word token and its token id in the input_text'''\n",
    "\n",
    "        m_doc = nlp(mention)\n",
    "        min_path_len = 1e10\n",
    "        lca = len(m_doc.sentences[-1].words) #last word of mention\n",
    "        lca_text = m_doc.sentences[-1].words[-1].text #last word of mention\n",
    "\n",
    "        mention_words = [w.text for w in m_doc.sentences[-1].words]\n",
    "        print(mention_words)\n",
    "        for sent in self.doc.sentences:\n",
    "            for word in sent.words:\n",
    "                if word.text not in mention_words:\n",
    "                    continue\n",
    "                path = self.paths[word.id]\n",
    "                print(word.text, path)\n",
    "                if len(path)<min_path_len:\n",
    "                    min_path_len = len(path)\n",
    "                    lca = word.id\n",
    "                    lca_text = word.text\n",
    "        return lca_text, lca\n",
    "            \n",
    "    def deduplicate(self, mentions):\n",
    "        mention_heads = {}\n",
    "        for m in mentions:\n",
    "            head = self.get_head_word(m)\n",
    "            if head in mention_heads.keys():\n",
    "                mention_heads[head].append(m)\n",
    "            else:\n",
    "                mention_heads[head] = [m]\n",
    "        mentions = [max(v, key = len) for v in mention_heads.values()]\n",
    "        return mentions\n",
    "    \n",
    "    def find_mentions(self):\n",
    "        mentions = []\n",
    "        for sentence in self.doc.sentences:\n",
    "            for word in sentence.words:\n",
    "                if word.pos not in ['PRON', 'NOUN', 'PROPN', 'NUM']:\n",
    "                    continue\n",
    "                mention_char_span = self.noun_phrase(word.id, [])\n",
    "                if(len(mention_char_span)!=0):\n",
    "                    mentions.append(text[mention_char_span[0]:mention_char_span[1]])\n",
    "        mentions = self.deduplicate(mentions)\n",
    "        return list(set(mentions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mao', 'Tse-tung']\n",
      "Mao [0, 6, 5, 2]\n",
      "Tse-tung [0, 6, 5, 2, 3]\n",
      "['Tse-tung']\n",
      "Tse-tung [0, 6, 5, 2, 3]\n",
      "['China']\n",
      "China [0, 6, 5]\n",
      "['1949']\n",
      "1949 [0, 6, 8]\n",
      "['a', 'partnership']\n",
      "a [0, 6, 11, 10]\n",
      "partnership [0, 6, 11]\n",
      "a [0, 6, 11, 14, 17, 16]\n",
      "['the', 'communists', 'and', 'a', 'number']\n",
      "a [0, 6, 11, 10]\n",
      "the [0, 6, 11, 14, 13]\n",
      "communists [0, 6, 11, 14]\n",
      "and [0, 6, 11, 14, 17, 15]\n",
      "a [0, 6, 11, 14, 17, 16]\n",
      "number [0, 6, 11, 14, 17]\n",
      "['a', 'number']\n",
      "a [0, 6, 11, 10]\n",
      "a [0, 6, 11, 14, 17, 16]\n",
      "number [0, 6, 11, 14, 17]\n",
      "['smaller', ',', 'non-communist', 'parties']\n",
      "smaller [0, 6, 11, 14, 17, 22, 19]\n",
      ", [0, 6, 11, 14, 17, 22, 20]\n",
      "non-communist [0, 6, 11, 14, 17, 22, 21]\n",
      "parties [0, 6, 11, 14, 17, 22]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1949',\n",
       " 'smaller, non-communist parties',\n",
       " 'China',\n",
       " 'Tse-tung',\n",
       " 'a partnership',\n",
       " 'the communists and a number',\n",
       " 'Mao Tse-tung']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '''Even Mao Tse-tung's China began in 1949 with a partnership between the communists and a number of smaller, non-communist parties.'''\n",
    "g = DepGraph(text)\n",
    "g.find_mentions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mao', 'Tse-tung']\n",
      "Mao [0, 6, 5, 2]\n",
      "Tse-tung [0, 6, 5, 2, 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Mao', 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.get_head_word('Mao Tse-tung')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "began\n",
      "China\n",
      "Mao\n",
      "Tse-tung\n"
     ]
    }
   ],
   "source": [
    "for idx in [6, 5, 2, 3]:\n",
    "    print(g.word_dict[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: [0, 6, 5, 2, 1],\n",
       " 3: [0, 6, 5, 2, 3],\n",
       " 4: [0, 6, 5, 2, 4],\n",
       " 2: [0, 6, 5, 2],\n",
       " 5: [0, 6, 5],\n",
       " 7: [0, 6, 8, 7],\n",
       " 8: [0, 6, 8],\n",
       " 9: [0, 6, 11, 9],\n",
       " 10: [0, 6, 11, 10],\n",
       " 12: [0, 6, 11, 14, 12],\n",
       " 13: [0, 6, 11, 14, 13],\n",
       " 15: [0, 6, 11, 14, 17, 15],\n",
       " 16: [0, 6, 11, 14, 17, 16],\n",
       " 18: [0, 6, 11, 14, 17, 22, 18],\n",
       " 19: [0, 6, 11, 14, 17, 22, 19],\n",
       " 20: [0, 6, 11, 14, 17, 22, 20],\n",
       " 21: [0, 6, 11, 14, 17, 22, 21],\n",
       " 22: [0, 6, 11, 14, 17, 22],\n",
       " 17: [0, 6, 11, 14, 17],\n",
       " 14: [0, 6, 11, 14],\n",
       " 11: [0, 6, 11],\n",
       " 23: [0, 6, 23],\n",
       " 6: [0, 6],\n",
       " 0: [0]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''Bob, John, and Mary saw him.'''\n",
    "g = DepGraph(text)\n",
    "g.find_mentions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''Some U.S. allies are complaining that President Bush is pushing conventional-arms talks too quickly, creating a risk that negotiators will make errors that could affect the security of Western Europe for years.'''\n",
    "g = DepGraph(text)\n",
    "g.find_mentions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''During the third quarter, Compaq purchased a former Wang Laboratories manufacturing facility in Sterling, Scotland, which will be used for international service and repair operations.'''\n",
    "g = DepGraph(text)\n",
    "g.find_mentions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''The government has other agencies and instruments for pursuing these other objectives.'''\n",
    "g = DepGraph(text)\n",
    "g.find_mentions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''happy campus president of Mass'''\n",
    "g = DepGraph(text)\n",
    "g.find_mentions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Tse-tung', 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.get_head_word('Tse-tung')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.noun_phrase(1, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''Bob, John, Mary saw him.'''\n",
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma,depparse')\n",
    "doc = nlp(text)\n",
    "print(*[f'id: {word.id}\\tword: {word.text}\\t\\tpos: {word.pos} \\t\\thead id: {word.head}\\t\\thead: {sent.words[word.head-1].text if word.head > 0 else \"root\"}\\tdeprel: {word.deprel}' for sent in doc.sentences for word in sent.words], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
